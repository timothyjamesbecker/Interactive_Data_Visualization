{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf16cc3-55db-47f2-a434-d0168f89b497",
   "metadata": {},
   "source": [
    "# Interactive Data Visualization\n",
    "##### (C) 2023-2025 Timothy James Becker: [revision 1.0](),  [GPLv3 license](https://www.gnu.org/licenses/gpl-3.0.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b85454-0da6-4285-b97a-ae5d7d98de1b",
   "metadata": {},
   "source": [
    "## <u>Time Visualization</u>\n",
    "\n",
    "Time can be an incredibly complex data type to work with, which is why we provide a dedicated treatment so that we can learn about the potential issues and how to correct them to be able to ethically visualize our results. In this section we will look at both preprocessing steps we can take for time-series analysis using the built in python3 [datetime](https://docs.python.org/3/library/datetime.html#) types which offer robust analysis (up to an including aggregation). For the visual component we will make use of the robust [d3 treatment of time](https://d3js.org/d3-time-format) which will use a well-established basis for working with time. Interestingly enough time is entirely dependence on spatial location in our world and as a result everything discussed in the [10_Spatial_Visualization.ipynb] is important to keep in mind. For example, one time point in a location (latitude, longitude) will have a different time on some coordinates but not others which is called the time zone. We will discuss this and how to handle this spatial component in the dedicated time analysis section.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/88/World_Time_Zones_Map.png\" alt=\"time zones\" width=\"1000px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c7a06b-6900-455b-866d-ee4346c473c7",
   "metadata": {},
   "source": [
    "#### <u>Coordinated Universal Time</u>\n",
    "\n",
    "Coordinated Universal Time or [UTC](https://en.wikipedia.org/wiki/Coordinated_Universal_Time) is the basis for dealing with time (synchronizing time reference points).  UTC is the elapsed time for a singular time reference point which is then offset (+ or -) based on the rotational coordinate (roughly). It does not include provisions for local time adjustments such as [Daylight Savings Time](https://en.wikipedia.org/wiki/Daylight_saving_time).  Each day has nearly 86400 (60 seconds * 60minutes * 24 hours) with the exception of leap seconds that are used to make adjustments to Earth rotation time or Universal Time [UT1](https://en.wikipedia.org/wiki/Universal_Time). Using the chart shown above you can see that CT lies within band UTC -4 and Japan is in UTC +9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c9058-711c-44ce-836b-1ff9ae4bc2a1",
   "metadata": {},
   "source": [
    "#### <u>Parsing Dates</u>\n",
    "\n",
    "Time needs to be in something like UTC in order for us to analyze or visualize it. We will start by looking at the process of reading in common date notations as strings and then converting them into a UTC aware numeric time type. Some commonly used date formats in the USA are:\n",
    "\n",
    "Month/Day/Year\n",
    "\n",
    "1/24/23\n",
    "\n",
    "or\n",
    "\n",
    "01/24/23\n",
    "\n",
    "or\n",
    "\n",
    "01/24/2023\n",
    "\n",
    "See how the different forms of a standard Month/Day/Year need to be better specified? Basically, we want to make sure we have a certain number of digits for Day, Month, Year which will make processing our dates easier and faster:\n",
    "\n",
    "MM/DD/YY (provides some understanding of how many digits for each, here there are 2)\n",
    "\n",
    "Lets use the python3 datetime library to work on some historical stock data AAPL_Historical_Data.csv which can be found in this OER repository data section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b823e0-7e6c-4eb7-a034-4f8cceb371d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Date', 'Close/Last', 'Volume', 'Open', 'High', 'Low'],\n",
       " [['11/07/2025', '$268.47', '48227370', '$269.795', '$272.29', '$266.77'],\n",
       "  ['11/06/2025', '$269.77', '51204050', '$267.89', '$273.40', '$267.89'],\n",
       "  ['11/05/2025', '$270.14', '43683070', '$268.61', '$271.70', '$266.93'],\n",
       "  ['11/04/2025', '$270.04', '49274850', '$268.325', '$271.486', '$267.615'],\n",
       "  ['11/03/2025', '$269.05', '50194580', '$270.42', '$270.85', '$266.25'],\n",
       "  ['10/31/2025', '$270.37', '86167120', '$276.99', '$277.32', '$269.16'],\n",
       "  ['10/30/2025', '$271.40', '69886530', '$271.99', '$274.14', '$268.48'],\n",
       "  ['10/29/2025', '$269.70', '51086740', '$269.275', '$271.41', '$267.11'],\n",
       "  ['10/28/2025', '$269.00', '41534760', '$268.985', '$269.89', '$268.15'],\n",
       "  ['10/27/2025', '$268.81', '44888150', '$264.88', '$269.12', '$264.6501']])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading in time-based stock data into python3 data analysis system using datetime\n",
    "with open('data/AAPL_Historical_Data.csv','r') as f:\n",
    "    raw = [row.replace('\\n','').split(',') for row in f.readlines()]\n",
    "header,raw = raw[0],raw[1:]\n",
    "header,raw[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9988df-09e1-406c-84df-216bdc70dea3",
   "metadata": {},
   "source": [
    "We will work with the first two columns for now which have the date and the closing price. We will make use of the datetime python library which has a nice string to time parser [strptime](https://docs.python.org/3/library/datetime.html#datetime.datetime.strptime). Notice that our data above follows a MM/DD/YYYY date pattern which will translate into our [parser syntax](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f4a20-35f2-48a8-aeb2-0ac6e3d95f84",
   "metadata": {},
   "source": [
    "How can we determine how each part of the date is structured in the input data? We can either look at it in a CSV viewer (carefully) and make some mistakes, or we can use a more data-orientated and error free approach (professional analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cafca45-2bcf-4f6b-baa6-75ade7d78e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
      "['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025']\n"
     ]
    }
   ],
   "source": [
    "# look at all the values for day, month and year using sets/fictionaries in python\n",
    "\n",
    "months = sorted(set([row[0].split('/')[0] for row in raw]))\n",
    "days   = sorted(set([row[0].split('/')[1] for row in raw]))\n",
    "years  = sorted(set([row[0].split('/')[2] for row in raw]))\n",
    "print(months)\n",
    "print(days)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83b158a0-815c-4ac7-ad30-a4c32aa1d5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 11, 7, 0, 0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue using python for datetime analysis\n",
    "from datetime import datetime as dt\n",
    "from datetime import timezone as tz\n",
    "from datetime import timedelta as td\n",
    "import numpy as np\n",
    "\n",
    "date = raw[0][0]\n",
    "d = dt.strptime(date,'%m/%d/%Y') #%m is zero-padded month, %d is zerp-padded day, %Y is four-digit year\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ed399d-b1c3-4645-9e1e-ff182b4a601b",
   "metadata": {},
   "source": [
    "Notice here that when a time is not given, it will default to the very start of the date provided: 12:00am (or 00:00 in military time). Similar to parsing dates we can also print them using [strftime](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "089df51e-39d7-4fd6-a63c-c30359c14fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07-11-25'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.strftime('%d-%m-%y') #now we output in day month year formate (popular in Europe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d41f9-9590-4628-b005-e023a8cf0281",
   "metadata": {},
   "source": [
    "Adding time components is similar where we have hours, minutes, seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6456fd22-b521-49e5-9679-4836e8d51395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2026, 12, 25, 6, 20, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = '12-25-26 06:20:02' #this is in month-day-year hours:minutes:seconds format\n",
    "d = dt.strptime(date,'%m-%d-%y %H:%M:%S')\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73141fa-e96f-4d1b-ab08-817aa9c3c8f7",
   "metadata": {},
   "source": [
    "Using this knowledge we can complete some analysis that would be hard to do otherwise: find the average closing price of the stocks per month (there are a variable number of days per month so you can't just take 30 days...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb611a6b-8c6e-4ea2-9bef-74a3fcf84897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[datetime.datetime(2025, 11, 7, 0, 0), 268.47],\n",
       " [datetime.datetime(2025, 11, 6, 0, 0), 269.77],\n",
       " [datetime.datetime(2025, 11, 5, 0, 0), 270.14],\n",
       " [datetime.datetime(2025, 11, 4, 0, 0), 270.04],\n",
       " [datetime.datetime(2025, 11, 3, 0, 0), 269.05],\n",
       " [datetime.datetime(2025, 10, 31, 0, 0), 270.37],\n",
       " [datetime.datetime(2025, 10, 30, 0, 0), 271.4],\n",
       " [datetime.datetime(2025, 10, 29, 0, 0), 269.7],\n",
       " [datetime.datetime(2025, 10, 28, 0, 0), 269.0],\n",
       " [datetime.datetime(2025, 10, 27, 0, 0), 268.81]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the data as datetime using strptime() and read closing price as float\n",
    "data = [[dt.strptime(row[0],'%m/%d/%Y'),float(row[1].replace('$',''))]for row in raw]\n",
    "data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ab6d82-21e8-4adf-8b40-a366f166b669",
   "metadata": {},
   "source": [
    "We should understand that the datetime type in python is sortable and works just like integers because the underlying structure is seconds since a reference point (UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26c38b55-1bd6-4ef5-b2b7-ff95b11b1652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[datetime.datetime(2015, 11, 10, 0, 0), 29.1925],\n",
       " [datetime.datetime(2015, 11, 11, 0, 0), 29.0275],\n",
       " [datetime.datetime(2015, 11, 12, 0, 0), 28.93],\n",
       " [datetime.datetime(2015, 11, 13, 0, 0), 28.085],\n",
       " [datetime.datetime(2015, 11, 16, 0, 0), 28.5437],\n",
       " [datetime.datetime(2015, 11, 17, 0, 0), 28.4225],\n",
       " [datetime.datetime(2015, 11, 18, 0, 0), 29.3225],\n",
       " [datetime.datetime(2015, 11, 19, 0, 0), 29.695],\n",
       " [datetime.datetime(2015, 11, 20, 0, 0), 29.825],\n",
       " [datetime.datetime(2015, 11, 23, 0, 0), 29.4375]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python can easily sort timeseries\n",
    "data = sorted(data, key=lambda x: x[0]) #this will sort based on earliest time to latest (past to present)\n",
    "data [0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da33e33-d818-4aff-b936-8722b0315020",
   "metadata": {},
   "source": [
    "Now we can gather all the data for each month (across all years):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "277c9c6f-a694-43a7-8a7a-c2dcf0e3ff11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11, 2015)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python object orientated datetime object have dot notation for instance variables\n",
    "d = data[0][0]\n",
    "d.day,d.month,d.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9dc6ef0-6305-4ee2-8b63-d4ab3df1c31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11: 110.51,\n",
       " 12: 109.77,\n",
       " 1: 107.43,\n",
       " 2: 109.51,\n",
       " 3: 105.04,\n",
       " 4: 105.87,\n",
       " 5: 106.99,\n",
       " 6: 108.56,\n",
       " 7: 118.78,\n",
       " 8: 122.01,\n",
       " 9: 124.35,\n",
       " 10: 125.96}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python find average month across years which has the highest close\n",
    "\n",
    "months = {} #dictionary to hold a list of datetime objects\n",
    "for d,p in data:\n",
    "    if d.month in months: months[d.month] += [p]\n",
    "    else:                 months[d.month]  = [p]\n",
    "        \n",
    "for m in months: months[m] = round(np.mean(months[m]),2)\n",
    "months #October is the highest average month of closing stock for Apple. Any ideas why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd1a23-a968-4393-a767-23c236bc94c6",
   "metadata": {},
   "source": [
    "#### <u>Time Zones</u>\n",
    "\n",
    "We can also add timezone information to our datetime objects so that we can compute more advanced temporal problems. Lets parse the data again but we will set the timezone as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d92aff40-3f16-4142-b806-0414a7bce982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timezone(datetime.timedelta(days=-1, seconds=72000))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#timezone python object\n",
    "tzone  = tz(td(hours=-4)) #for Eastern offset from UTC in the chart\n",
    "tzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cbb946d6-5183-4502-9862-c6cf6d466726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[datetime.datetime(2025, 11, 7, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  268.47],\n",
       " [datetime.datetime(2025, 11, 6, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  269.77],\n",
       " [datetime.datetime(2025, 11, 5, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  270.14],\n",
       " [datetime.datetime(2025, 11, 4, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  270.04],\n",
       " [datetime.datetime(2025, 11, 3, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  269.05],\n",
       " [datetime.datetime(2025, 10, 31, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  270.37],\n",
       " [datetime.datetime(2025, 10, 30, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  271.4],\n",
       " [datetime.datetime(2025, 10, 29, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  269.7],\n",
       " [datetime.datetime(2025, 10, 28, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  269.0],\n",
       " [datetime.datetime(2025, 10, 27, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000))),\n",
       "  268.81]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the timezone aware object to make your data analysis timezone aware\n",
    "data = [[dt.strptime(row[0],'%m/%d/%Y').replace(tzinfo=tzone),float(row[1].replace('$',''))]for row in raw]\n",
    "data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1683dc-d174-4643-b698-e77e1f09ce8f",
   "metadata": {},
   "source": [
    "#### <u>Time Delta</u>\n",
    "\n",
    "A core operation in any temporal analysis is dealing with the distance between times or more simply: the time delta (time difference or change in time which delta usually represents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bbd8ed10-681f-4d65-b826-6c858b12333d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=3650)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python has comprehensive timezone aware distance built in!\n",
    "\n",
    "data[0][0]-data[-1][0] #data span of this data is around ~10 years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd0584-dc76-41b5-a74c-0037337b5267",
   "metadata": {},
   "source": [
    "#### <u>Using D3 time formatting to manipulate time</u>\n",
    "\n",
    "We will also look at using [d3 time formatting](https://d3js.org/d3-time-format) for parsing CSV files as well. In general, when the data is not nice and has to be fixed, you should use something like python while once the data has been fixed it can be fed into a d3 web app. Here we will switch over to the HTML/JS d3 stack to show how d3 can directly manipulate date/time data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b1a732e-f67a-4823-b86d-95e032e056bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"dd1\"></div>\n",
       "\n",
       "<script type=\"module\"> \n",
       "    import * as d3 from \"https://cdn.skypack.dev/d3@7\"; \n",
       "    const date  = \"11/07/2025\";\n",
       "    const parse = d3.utcParse(\"%m/%d/%Y\");\n",
       "    alert(parse(date));\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<div id=\"dd1\"></div>\n",
    "\n",
    "<script type=\"module\"> \n",
    "    import * as d3 from \"https://cdn.skypack.dev/d3@7\"; \n",
    "    const date  = \"11/07/2025\";\n",
    "    const parse = d3.utcParse(\"%m/%d/%Y\");\n",
    "    alert(parse(date));\n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dbc7f9-4fbb-4f37-8a24-67672c43e179",
   "metadata": {},
   "source": [
    "Try the example above and play around with extracting different date formats (there are exercises that you can do in this cell here at the end of this section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da519b8-ab3c-4833-a4f2-1629dd572d6c",
   "metadata": {},
   "source": [
    "Let’s build a new d3 based line graph that will consume the AAPL stocks one year at a time, knowing that we have actually 10 years of data. If we now manipulate our data appropriately, we can provide numerous visual insights into year stock visualization.  First, we will start with a fresh [d3 web app](https://github.com/timothyjamesbecker/Interactive_Data_Visualization/tree/main/d3_template_webapp) which you can download or make a copy of to start. You then should download the [AAPL_Historical_Data.csv]() from the data folder and put it inside your web app folder so that the d3 library can see it using a relative path. We will write a basic CSV data loader and use our d3 time parser to convert all data into [d3 time](https://d3js.org/d3-time) objects. Once we are there, we can then process them by year to gather multiple years of data, or write a more complex framework that would allow each year to be selected for visualization.\n",
    "\n",
    "<img src=\"figures/webstorm_aapl_time.png\" alt=\"webstorm aapl time\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac74952-22ab-4ea7-833d-e928e2d57146",
   "metadata": {},
   "source": [
    "If we didn't have the ability to manipulate time data, we would simply visualize the data over the course of all tens years using a line plot:\n",
    "\n",
    "<img src=\"figures/aapl_10_years.png\" alt=\"aapl ten years\" width=\"800px\">\n",
    "\n",
    "But what if we want to look and compare each year-to-year growth? That is a more difficult task and one that will require working with our data based on its time. Mainly how do we organize the time series when we want to compare one year to another?  One way we will employ is to pull out the year for each data point and use it as a key into a separate data structure (dictionary in python) that will basically partition the data by year.  If we simply chop the data by year we won't see the overall yearly growth and so we can also normalize and even standardize it to get a better visual result of year-to-year performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18daa24e-353e-4c61-8f26-73f368d845e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_yearly(data){\n",
    "    let new_data = {};\n",
    "    for(let i=0; i<data.length; i++){\n",
    "        let k = data[i].date.getUTCFullYear();\n",
    "        let d = new Date(2025,Number(d3.timeFormat('%m')(data[i].date))-1,d3.timeFormat('%d')(data[i].date));\n",
    "        if(k in new_data){ new_data[k].push({'date':d,'close':data[i].close,'volume':data[i].volume});}\n",
    "        else { new_data[k] = [{'date':d,'close':data[i].close,'volume':data[i].volume}]; }\n",
    "    }\n",
    "    for(let k in new_data){\n",
    "        let m = d3.mean(new_data[k],(d)=>{ return d.close; })                        //mean\n",
    "        let s = Math.pow(d3.sum(new_data[k],(d)=>{ return (d.close-m)**2; }),0.5) //stdev\n",
    "        for(let i=0; i<new_data[k].length; i++){\n",
    "            new_data[k][i].close = (new_data[k][i].close-m)/s;\n",
    "        }\n",
    "    }\n",
    "    return new_data;\n",
    "}\n",
    "\n",
    "d3.dsv(\",\", \"AAPL_Historical_Data.csv\", (d) => {\n",
    "    return {\n",
    "        date:    d3.utcParse(\"%m/%d/%Y\")(d.Date),\n",
    "        close:  +d['Close/Last'].replace(\"$\",\"\"),\n",
    "        volume: +d.Volume\n",
    "    };\n",
    "}).then((data,err)=>{\n",
    "    //draw out d3 code here \n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072741c-6a9a-4512-9472-9e05b6624128",
   "metadata": {},
   "outputs": [],
   "source": [
    "//this is the draw code that goes in the cell placement above\n",
    "\n",
    "let new_data = get_yearly(data);\n",
    "let close = [0,0];\n",
    "for(let k in new_data){\n",
    "    let mx = [d3.min(new_data[k],(d)=>{return d.close;}),d3.max(new_data[k],(d)=>{return d.close;})];\n",
    "    if(mx[0]<=close[0]){close[0]=mx[0];}\n",
    "    if(mx[1]>=close[1]){close[1]=mx[1];}\n",
    "}\n",
    "console.log(close)\n",
    "let height = 800, width = 1200;\n",
    "var svg = d3.select(\"#div1\")\n",
    "    .append(\"svg\").attr(\"width\", width+40).attr(\"height\", height+40)\n",
    "    .append(\"g\").attr(\"transform\",\"translate(\"+80+\",\"+0+\")\");\n",
    "\n",
    "var x = d3.scaleTime()\n",
    "    .domain([new Date(2025,0,1), new Date(2025,11,31)]).range([0, width])\n",
    "svg.append(\"g\")\n",
    "    .attr(\"transform\", \"translate(0,\"+height+\")\").call(d3.axisBottom(x).ticks(d3.timeMonth.every(1)) // One tick for each month\n",
    "    .tickFormat(d3.timeFormat(\"%B\")));\n",
    "var y = d3.scaleLinear()\n",
    "    .domain(close).range([height, 0]);\n",
    "svg.append(\"g\").call(d3.axisLeft(y));\n",
    "\n",
    "var colors = {2016:'#9e0142',2017:'#d53e4f',2018:'#f46d43',2019:'#fdae61',2020:'#fee08b',\n",
    "              2021:'#e6f598',2022:'#abdda4',2023:'#66c2a5',2024:'#3288bd',2025:'#5e4fa2'};\n",
    "for(let k in new_data) {\n",
    "    svg.append(\"path\")\n",
    "        .datum(new_data[k])\n",
    "        .attr(\"fill\", \"none\").attr(\"stroke\", colors[k]).attr(\"stroke-width\", 2)\n",
    "        .attr(\"d\", d3.line().curve(d3.curveBundle.beta(0.0)) //lower beta towards 0 to see its smoothing effects\n",
    "            .x(function (d) {return x(d.date)})\n",
    "            .y(function (d) {return y(d.close)})\n",
    "        );\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b04e9b-6518-4747-99c2-fe32754da62f",
   "metadata": {},
   "source": [
    "First, we define a function to gather all the months of data for each of the ten years. We use an object with the true year as the key and then extract the month and day values by using the Number(d3.timeFormat('%m'))-1 which sets it to the weird month index that is required by the JavaScript Date object. Once we have built a dictionary of all the monthly datasets, we can normalize them to the mean which will center all the years at zero. After that they get divided by the standard deviation which will also scale each year to its local making each year vastly more comparable to each other year. Finally, we apply some curvature to the resulting lines so that we can control the ability to look at each year’s trend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ee80a-a454-479e-b5ab-80674e15d38e",
   "metadata": {},
   "source": [
    "<img src=\"figures/aapl_d3_std.png\" alt=\"aapl d3 std\" width=\"800px\">\n",
    "\n",
    "When we change the beta value from 1.0 toward 0 we will see how the stock performed over time. The results will show only two of the ten years had a negative trending stock: 2019 and 2024.\n",
    "\n",
    "<img src=\"figures/aapl_d3_std_beta.png\" alt=\"aapl d3 std beta\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa058d8e-7aa7-442a-acaa-d87176cd46ac",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "#### [1] Get some practice with the python3 datetime parser as shown in the beginning of this section. Try to parse the following examples: \n",
    "\n",
    "\"March 27th, 2008\"\n",
    "\n",
    "\"1/23/15 23:21:01\"\n",
    "\n",
    "\"02/12/97\"\n",
    "\n",
    "\"1:22pm, Tuesday, November 11th, 2025\"\n",
    "\n",
    "#### [2] Starting with the AAPL datset above, try experimenting to visualize another column variable (volume, opening cost, etc)\n",
    "#### [3] Using a different stock data from the github repo (such as NVDA_Historical_Data.csv) complete the same visualization and look for any bad performance (negative line) years.\n",
    "#### [4] Redo the color choices shown here so that it uses a d3-color scale. If you manage that you can then easily add a [d3 legend](https://observablehq.com/@d3/color-legend) to the plot to show which years are low-performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c929d-1c2e-4604-a80a-bce35df946de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
